

### 1.事物

​	原子性（Atomicity）	一致性（Consistency）	隔离性（Isolation）	持久性（Durability）
​	脏读	幻读	不可重复读

### 2.对分布式事务的理解

​	一个操作可能调用多个服务模块的服务，为保持数据的一致性和完整性，必须保证事务，失败时必须对操作进行回滚

### 3.分布式事务

​	**1）两阶段提交：**基于事务协调器(事务管理器)来统一掌控所有节点(称作参与者)的操作结果并最终指示这些节点是否要把操作结果进行真正的提交。
​		算法思路：参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情况决定各参与者是否要提交操作还是中止操作。
​		准备阶段：事务协调者(事务管理器)给每个参与者(资源管理器)发送 Prepare 消息，每个参与者要么直接返回失败(如权限验证失败)，要么校验通过在本地执行事务，写本地的 redo 和 undo 日志，但不提交，到达一种“万事俱备，只欠东风”的状态。
​		提交阶段：如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。(注意:必须在最后阶段释放锁资源)
​		缺点：
​			同步阻塞问题、单点故障、数据不一致（脑裂问题）、二阶段无法解决的问题

​	**2）三阶段提交：**
​		和两阶段提交差不多，与两阶段提交不同的是，三阶段提交有两个改动点：
​		1、引入超时机制。同时在协调者和参与者中都引入超时机制。
​		2、把两段提交准备阶段拆分为CanCommit 阶段、PreCommit 阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。

​	**3）TCC 型事务（Try/Confirm/Cancel）：**可以归为补偿型
​		执行中有异常则在catch中做成功事务的状态回滚。假如A,B两个事务，A成功，B失败，则catch做A事务记录状态回滚补偿。
​		
​	**4）异步确保型**
​		执行本地事务前向MQ发一条half消息(此消息暂不投递给消费方)，half消息成功后执行本地事务，本地事务成功后再向MQ发送一条commit消息，MQ再把这条消息投递给消费方。
​		
​	**5）最大努力通知型（多次尝试）：**和异步确保型不一样就是允许规定次数后事务失败。

### 4.分布式session

​	1）Session复制与共享	缺点：1.数据量大情况下，web容器压力加大；	2.延迟问题；
​	2）客户端存储法 		缺点：1.消耗网络资源；						2.客户端信息伪造危险；
​	3）反向代理一致性hash	缺点：1.集群扩容、缩容量下对一致性hash结果破坏；2.并不能保证压力比较均匀，如：有的客户是频繁访问，有的客户是频率低；
​	4）服务端集中存储到数据库或缓存

### 5.项目如何做高可用

​	资料：https://www.cnblogs.com/huojg-21442/articles/10887939.html
​		https://juejin.im/post/6844903897627099144#heading-23
​	核心目的：
​		1）拒绝单点问题：部分服务节点挂了之后，整体任然能够对外提供服务
​		2）拒绝服务器压垮：保证系统高并发下的高吞吐、高性能。

​	高可用的主要手段是冗余，服务冗余，数据冗余，中间件冗余，能够自动进行失效转移。

> **1）服务高可用：**
> 	服务冗余：集群部署，多台服务，分开部署，自动失效转移，无单点问题
> 	服务无状态化：以便随时扩容，减轻集群压力
> 	服务容错：做好限流、熔断、降级
> 	
> **2）中间件高可用：**
> 	服务注册中心：
> 		zookeeper奇数台集群部署，防脑裂，自动选主（paxios算法），无单点问题。
> 	缓存高可用：
> 		redis奇数台集群部署，防脑裂，自动选主（哨兵模式），无单点问题
> 		数据分片提升性能
> 	mq高可用：
> 		异步处理、流量削峰，加大吞吐
> 		rocketmq双主模式部署，无单点问题，数据无丢失，消息可回溯
> 		
> **3）数据库高可用：**
> 	主备切换：故障自动切换、无单点问题；
> 	主从复制、读写分离、分库分表（来分散压力，优化检索，提升性能），数据冗余（保证数据安全）

> 开发质量控制：通过自动化版本管理、自动化验证、预发布验证、自动化发布、灰度发布等手段减少故障引入线上的可能。
> 运行监控保证：通过业务监控，服务器性能监控，保证服务出错后能第一时间察觉。

### 6.什么是分布式锁

​	资料：https://blog.csdn.net/yb223731/article/details/90349502
​	目的：分布式锁是为了做业务幂等。
​	本质：先执行的线程设置一个标记，其它线程执行前发现标记存在表示获取锁失败，标记不存在则获取锁成功，同时设置标记到redis完成加锁，执行完成执行清除。
​	具体实现：jedis的set方法可以多参数，调用时传入key和过期时间（相当与setnx，和expire的组合），当且仅当key不存在的时候会设置值，已存在则不作任何操作，并且带返回结果。
​	原则：互斥性，不会发生死锁，具有容错性，解铃还须系铃人

### 7.有哪几层能做负载均衡

​	通常大型网站会做多级
​	1）应用层：
​		反向代理：
​		rpc框架：
​		http重定向：
​		DNS解析：
​	2）传输层：反向代理
​	3）网络层：负载均衡服务器修改目标ip
​	4）数据链路层：修改mac地址

### 8.nginx是工作再哪一层的？

​	通常我们用它做http代理，就是应用层代理，也可以做传输层代理，配置下upstream模块就行。

### 9.负载均衡算法

​	随机、轮询、权重、一致性hash、最少连接。

### 10.服务限流、熔断、降级

​	资料：https://mp.weixin.qq.com/s?__biz=MzIwODA4NjMwNA==&mid=2652897781&idx=1&sn=ae121ce4c3c37b7158bc9f067fa024c0&scene=21#wechat_redirect
​		https://mp.weixin.qq.com/s?__biz=MzIwODA4NjMwNA==&mid=2652897782&idx=1&sn=cb46b23b2778f14ea3bcc419eb0392ce&scene=21#wechat_redirect

##### 	限流：

​		限流方式很多，但原理大都相同，都是基于我们限流算法去做的
​		限流算法
​			常见的限流算法有：令牌桶、漏桶。计数器也可以进行粗暴限流实现。

> ​	**1）应用级限流（单机限流）**
> ​		1.限流对外总并发数：如tomcat：maxConnections： 最大连接数，超出的会排队等待，超出等待数的会拒绝；另外如Mysql（如max_connections）、Redis（如tcp-backlog）都会有类似的限制连接数的配置。
> ​		2.限流内部总资源数：如数据库连接、线程；线程池可以设置最大连接和workquee，连接满后进入workquee，超出workquee则执行拒绝策略；
> ​		3.限流接口总请求数：通过原子变量来计数控制；
> ​		4.限流接口请求速度：谷歌guva的RateLimiter有提供基于令牌桶和漏桶算法的实现。
> ​	**2）分布式限流（集群限流）**
> ​		1.redis+lua实现中的lua脚本：
> ​		2.使用Nginx+Lua实现的Lua脚本：
> ​		3.集群总并发数，redis存总数控制
> ​		Lua本身就是一种编程语言，也可以使用它实现复杂的令牌桶或漏桶算法。
> ​	**3）接入层限流**
> ​		接入层通常指请求流量的入口，该层的主要目的有：负载均衡、非法请求过滤、请求聚合、缓存、降级、限流、A/B测试、服务质量监控等等
> ​		1.nginx:自带有两个限流模块，
> ​			ngx_http_limit_conn_module：
> ​			ngx_http_limit_req_module：
> ​		2.还可以使用OpenResty提供的Lua限流模块lua-resty-limit-traffic进行更复杂的限流场景。

##### 降级：

​		目的：容错、高可用、有损服务：当访问量剧增，服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证核心服务还是可用的，即使是有损服务，而不是不服务。
​		资料：https://mp.weixin.qq.com/s?__biz=MzIwODA4NjMwNA==&mid=2652897793&idx=1&sn=850a1e8e11c5e1f6d4387713e1f1ddf8&scene=21#wechat_redirect

> ​	**自动降级：**根据系统负载、资源使用情况、请求响应时间、失败率统计。
> ​			1.关闭非核心服务：如淘宝双11，关闭部分评价服务，爬虫服务等等。
> ​			2.限流降级：如秒杀情况加，限制访问量，当达到限流阀值直接返回结束页面。
> ​	**人工降级：**
> ​			策略一样，只是手动控制，灰度开关等。
> ​			

##### 隔离：

​	目的：限定故障影响范围：为了在系统发生故障时能限定传播范围和影响范围，即发生故障后不会出现滚雪球效应
​	资料：https://mp.weixin.qq.com/s?__biz=MzIwODA4NjMwNA==&mid=2652898010&idx=1&sn=beecea98342cd183084cc73dded7aa98&chksm=8cdcd695bbab5f8333fc5177c7111fcb81dbe8de7ad39eda519fb8db97b555b658cde9dfbb9a&scene=21#wechat_redirect

> ​	线程隔离、进程隔离、集群隔离、机房隔离、读写隔离、动静隔离、爬虫隔离等。

### 11.Tomcat的优化经验：架构、服务器、Tomcat本身

​	资料：https://blog.csdn.net/lhzhktk/article/details/65937685
​	1）设置jvm内存
​	2）利用nginx缓存和压缩，对静态页面缓存，加速读取；对文件进行压缩，加速度网络通信。
​	3）优化tomcat参数，主要是优化连接配置，超时时间设置，关闭客户端dns查询。
​	4）服务器资源，服务器所能提供CPU、内存、硬盘的性能对处理能力有决定性影响。
​	5）采用集群，分摊压力。

> 控制Tomcat并发连接数目
> 资料：https://blog.csdn.net/a19860903/article/details/51554771
> 在tomcat配置文件server.xml中的<Connector ... />配置中
> 	minProcessors：最小空闲连接线程数，用于提高系统处理性能，默认值为10
> 	maxProcessors：最大连接线程数，即：并发处理的最大请求数，默认值为75
> 	acceptCount：允许的最大连接数，应大于等于maxProcessors，默认值为100
> 	enableLookups：是否反查域名，取值为：true或false。为了提高处理能力，应设置为false
> 	connectionTimeout：网络连接超时，
> 	
> nginx缓存和动静分离
> 	资料：https://segmentfault.com/a/1190000020475756
> 		https://blog.csdn.net/h13140995776/article/details/101174283
> 		https://blog.csdn.net/xiaoxiao_yingzi/article/details/93197397
> 		https://www.cnblogs.com/lvcisco/p/11606670.html
> 	缓存：对部分访问的页面，nginx本地磁盘创建一个副本，以后在有效期之内都去读副本
> 	动静分离：传统方式把前端资源放在web服务器上，会给web服务器带来压力。为了优化，做动静分离，静态资源放在nginx，而动态数据通过ajax异步获取。

### 12.接口的幂等性的概念 

​	同一操作多次请求，只执行一次操作，只。例如扫码付款：支付成功，但是返回的时候网卡，用户就点击，相当于发多个请求，要做到幂等性就是不能重复扣款。例如token方式，支付前先获取tokenid,一个id只用一次（不管成功失败）。